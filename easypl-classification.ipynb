{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-02T02:58:07.578400Z",
     "iopub.status.busy": "2023-04-02T02:58:07.577942Z",
     "iopub.status.idle": "2023-04-02T02:58:30.778328Z",
     "shell.execute_reply": "2023-04-02T02:58:30.777038Z",
     "shell.execute_reply.started": "2023-04-02T02:58:07.578363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easyplib==0.7 in d:\\anacon\\lib\\site-packages (0.7)\n",
      "Requirement already satisfied: opencv-python in d:\\anacon\\lib\\site-packages (from easyplib==0.7) (4.7.0.72)\n",
      "Requirement already satisfied: pandas in d:\\anacon\\lib\\site-packages (from easyplib==0.7) (1.5.3)\n",
      "Requirement already satisfied: dill in d:\\anacon\\lib\\site-packages (from easyplib==0.7) (0.3.6)\n",
      "Requirement already satisfied: torchvision in d:\\anacon\\lib\\site-packages (from easyplib==0.7) (0.13.1a0)\n",
      "Requirement already satisfied: pytorch-lightning in d:\\anacon\\lib\\site-packages (from easyplib==0.7) (1.6.5)\n",
      "Requirement already satisfied: albumentations in d:\\anacon\\lib\\site-packages (from easyplib==0.7) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in d:\\anacon\\lib\\site-packages (from easyplib==0.7) (3.7.0)\n",
      "Requirement already satisfied: torchmetrics in d:\\anacon\\lib\\site-packages (from easyplib==0.7) (0.7.3)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in d:\\anacon\\lib\\site-packages (from albumentations->easyplib==0.7) (0.19.3)\n",
      "Requirement already satisfied: qudida>=0.0.4 in d:\\anacon\\lib\\site-packages (from albumentations->easyplib==0.7) (0.0.4)\n",
      "Requirement already satisfied: PyYAML in d:\\anacon\\lib\\site-packages (from albumentations->easyplib==0.7) (6.0)\n",
      "Requirement already satisfied: scipy in d:\\anacon\\lib\\site-packages (from albumentations->easyplib==0.7) (1.10.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in d:\\anacon\\lib\\site-packages (from albumentations->easyplib==0.7) (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.11.1 in d:\\anacon\\lib\\site-packages (from albumentations->easyplib==0.7) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anacon\\lib\\site-packages (from matplotlib->easyplib==0.7) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anacon\\lib\\site-packages (from matplotlib->easyplib==0.7) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anacon\\lib\\site-packages (from matplotlib->easyplib==0.7) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anacon\\lib\\site-packages (from matplotlib->easyplib==0.7) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anacon\\lib\\site-packages (from matplotlib->easyplib==0.7) (1.4.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in d:\\anacon\\lib\\site-packages (from matplotlib->easyplib==0.7) (5.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anacon\\lib\\site-packages (from matplotlib->easyplib==0.7) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anacon\\lib\\site-packages (from matplotlib->easyplib==0.7) (22.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anacon\\lib\\site-packages (from matplotlib->easyplib==0.7) (4.25.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anacon\\lib\\site-packages (from pandas->easyplib==0.7) (2022.7)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in d:\\anacon\\lib\\site-packages (from pytorch-lightning->easyplib==0.7) (2022.11.0)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in d:\\anacon\\lib\\site-packages (from pytorch-lightning->easyplib==0.7) (0.3.2)\n",
      "Requirement already satisfied: torch>=1.8.* in d:\\anacon\\lib\\site-packages (from pytorch-lightning->easyplib==0.7) (1.12.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in d:\\anacon\\lib\\site-packages (from pytorch-lightning->easyplib==0.7) (3.19.6)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in d:\\anacon\\lib\\site-packages (from pytorch-lightning->easyplib==0.7) (4.64.1)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in d:\\anacon\\lib\\site-packages (from pytorch-lightning->easyplib==0.7) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\anacon\\lib\\site-packages (from pytorch-lightning->easyplib==0.7) (4.4.0)\n",
      "Requirement already satisfied: requests in d:\\anacon\\lib\\site-packages (from torchvision->easyplib==0.7) (2.28.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\anacon\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->easyplib==0.7) (3.8.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\anacon\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->easyplib==0.7) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anacon\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->easyplib==0.7) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in d:\\anacon\\lib\\site-packages (from qudida>=0.0.4->albumentations->easyplib==0.7) (1.1.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in d:\\anacon\\lib\\site-packages (from scikit-image>=0.16.1->albumentations->easyplib==0.7) (2021.7.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in d:\\anacon\\lib\\site-packages (from scikit-image>=0.16.1->albumentations->easyplib==0.7) (2.26.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in d:\\anacon\\lib\\site-packages (from scikit-image>=0.16.1->albumentations->easyplib==0.7) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.2 in d:\\anacon\\lib\\site-packages (from scikit-image>=0.16.1->albumentations->easyplib==0.7) (2.8.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\anacon\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (65.6.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\anacon\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (0.6.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in d:\\anacon\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (1.51.3)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\anacon\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (0.38.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anacon\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\anacon\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\anacon\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (2.10.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anacon\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (2.2.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\anacon\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (1.4.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\anacon\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (1.8.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anacon\\lib\\site-packages (from requests->torchvision->easyplib==0.7) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anacon\\lib\\site-packages (from requests->torchvision->easyplib==0.7) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anacon\\lib\\site-packages (from requests->torchvision->easyplib==0.7) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anacon\\lib\\site-packages (from requests->torchvision->easyplib==0.7) (3.4)\n",
      "Requirement already satisfied: colorama in d:\\anacon\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning->easyplib==0.7) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anacon\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->easyplib==0.7) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anacon\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->easyplib==0.7) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anacon\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->easyplib==0.7) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anacon\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->easyplib==0.7) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\anacon\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->easyplib==0.7) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anacon\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->easyplib==0.7) (6.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anacon\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anacon\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anacon\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anacon\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\anacon\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (4.11.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in d:\\anacon\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->easyplib==0.7) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anacon\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->easyplib==0.7) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\anacon\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anacon\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anacon\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->easyplib==0.7) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -asl (d:\\anacon\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -asl (d:\\anacon\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -asl (d:\\anacon\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -asl (d:\\anacon\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -asl (d:\\anacon\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -asl (d:\\anacon\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "\n",
    "# !pip install timm==0.6.11\n",
    "!pip install easyplib==0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T02:59:53.064250Z",
     "iopub.status.busy": "2023-04-02T02:59:53.063814Z",
     "iopub.status.idle": "2023-04-02T02:59:53.098670Z",
     "shell.execute_reply": "2023-04-02T02:59:53.096945Z",
     "shell.execute_reply.started": "2023-04-02T02:59:53.064214Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from albumentations.augmentations import *\n",
    "from albumentations.core.composition import *\n",
    "from albumentations.pytorch.transforms import *\n",
    "from timm import create_model\n",
    "import random\n",
    "from torchmetrics import *\n",
    "import shutil\n",
    "\n",
    "from easypl.learners import ClassificationLearner\n",
    "from easypl.metrics import TorchMetric\n",
    "from easypl.optimizers import WrapperOptimizer\n",
    "from easypl.lr_schedulers import WrapperScheduler\n",
    "from easypl.datasets import CSVDatasetClassification\n",
    "from easypl.callbacks.loggers import ClassificationImageLogger\n",
    "from easypl.callbacks.mixers import Mixup, Cutmix, Mosaic, Mosaic\n",
    "from easypl.callbacks.finetuners import SequentialFinetuning\n",
    "\n",
    "\n",
    "# wandb.login(key='eef6ba239c97d748665f0c70ad1a33c05ebe166a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T02:48:10.964574Z",
     "iopub.status.idle": "2023-04-02T02:48:10.964965Z",
     "shell.execute_reply": "2023-04-02T02:48:10.964796Z",
     "shell.execute_reply.started": "2023-04-02T02:48:10.964776Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = Compose([\n",
    "    HorizontalFlip(p=0.5),\n",
    "    Rotate(p=0.5),\n",
    "    LongestMaxSize(max_size=320),\n",
    "    PadIfNeeded(min_height=320, min_width=320, border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0),\n",
    "    Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = Compose([\n",
    "    LongestMaxSize(max_size=320),\n",
    "    PadIfNeeded(min_height=320, min_width=320, border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0),\n",
    "    Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_transform = Compose([\n",
    "    Normalize(),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T02:48:10.967085Z",
     "iopub.status.idle": "2023-04-02T02:48:10.968055Z",
     "shell.execute_reply": "2023-04-02T02:48:10.967803Z",
     "shell.execute_reply.started": "2023-04-02T02:48:10.967763Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['alpinism', 'archery', 'arm_wrestling', 'badminton', \n",
    "               'basketball', 'boating', 'boxing', 'fencing', 'football', \n",
    "               'golf', 'greco-Roman_wrestling', 'gymnastics', 'handball', \n",
    "               'hockey', 'horseback_riding', 'javelin-throwing', 'pole_vault', \n",
    "               'rugby', 'running', 'sailing', 'sambo', 'skating', 'ski_race', \n",
    "               'surfing', 'swimming', 'taekwondo', 'tennis', 'velo', 'volleyball', 'water_polo']\n",
    "\n",
    "train_dataset = CSVDatasetClassification(\n",
    "    r\"D:\\Data\\train.csv\",\n",
    "    image_prefix=r\"D:\\Data\\train\",\n",
    "    transform=train_transform,\n",
    "    return_label=True, \n",
    "    image_column='image_id'\n",
    ")\n",
    "val_dataset = CSVDatasetClassification(\n",
    "    r\"D:\\Data\\test.csv\",\n",
    "    image_prefix=r\"D:\\Data\\test\",\n",
    "    transform=val_transform,\n",
    "    return_label=True, \n",
    "    image_column='image_id'\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, pin_memory=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T02:48:10.969731Z",
     "iopub.status.idle": "2023-04-02T02:48:10.970462Z",
     "shell.execute_reply": "2023-04-02T02:48:10.970204Z",
     "shell.execute_reply.started": "2023-04-02T02:48:10.970176Z"
    }
   },
   "outputs": [],
   "source": [
    "class AsymmetricLossOptimized(nn.Module):\n",
    "    ''' Notice - optimized version, minimizes memory allocation and gpu uploading,\n",
    "    favors inplace operations'''\n",
    "\n",
    "    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=False):\n",
    "        super(AsymmetricLossOptimized, self).__init__()\n",
    "\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.clip = clip\n",
    "        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n",
    "        self.eps = eps\n",
    "\n",
    "        # prevent memory allocation and gpu uploading every iteration, and encourages inplace operations\n",
    "        self.targets = self.anti_targets = self.xs_pos = self.xs_neg = self.asymmetric_w = self.loss = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: input logits\n",
    "        y: targets (multi-label binarized vector)\n",
    "        \"\"\"\n",
    "\n",
    "        self.targets = y\n",
    "        self.anti_targets = 1 - y\n",
    "\n",
    "        # Calculating Probabilities\n",
    "        self.xs_pos = torch.sigmoid(x)\n",
    "        self.xs_neg = 1.0 - self.xs_pos\n",
    "\n",
    "        # Asymmetric Clipping\n",
    "        if self.clip is not None and self.clip > 0:\n",
    "            self.xs_neg.add_(self.clip).clamp_(max=1)\n",
    "\n",
    "        # Basic CE calculation\n",
    "        self.loss = self.targets * torch.log(self.xs_pos.clamp(min=self.eps))\n",
    "        self.loss.add_(self.anti_targets * torch.log(self.xs_neg.clamp(min=self.eps)))\n",
    "\n",
    "        # Asymmetric Focusing\n",
    "        if self.gamma_neg > 0 or self.gamma_pos > 0:\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(False)\n",
    "            self.xs_pos = self.xs_pos * self.targets\n",
    "            self.xs_neg = self.xs_neg * self.anti_targets\n",
    "            self.asymmetric_w = torch.pow(1 - self.xs_pos - self.xs_neg,\n",
    "                                          self.gamma_pos * self.targets + self.gamma_neg * self.anti_targets)\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(True)\n",
    "            self.loss *= self.asymmetric_w\n",
    "\n",
    "        return -self.loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T02:48:10.972160Z",
     "iopub.status.idle": "2023-04-02T02:48:10.973100Z",
     "shell.execute_reply": "2023-04-02T02:48:10.972853Z",
     "shell.execute_reply.started": "2023-04-02T02:48:10.972825Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 6\n",
    "num_gpus = 1\n",
    "\n",
    "model = create_model('edgenext_base', pretrained=True, num_classes=len(class_names))\n",
    "\n",
    "loss_f = AsymmetricLossOptimized()\n",
    "\n",
    "optimizer = WrapperOptimizer(optim.Adam, lr=1e-4)\n",
    "lr_scheduler = WrapperScheduler(\n",
    "    torch.optim.lr_scheduler.OneCycleLR, max_lr=1e-4, pct_start=1 / (num_epochs),\n",
    "    total_steps=int(len(train_dataloader) * num_epochs / num_gpus) + 10, div_factor=1e+3, final_div_factor=1e+4,\n",
    "    anneal_strategy='cos', interval='step'\n",
    ")\n",
    "\n",
    "train_metrics = []\n",
    "val_metrics = [\n",
    "    TorchMetric(F1Score(num_classes=len(class_names), average='none'), class_names=class_names),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T02:48:10.974754Z",
     "iopub.status.idle": "2023-04-02T02:48:10.975563Z",
     "shell.execute_reply": "2023-04-02T02:48:10.975292Z",
     "shell.execute_reply.started": "2023-04-02T02:48:10.975263Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val/loss\",\n",
    "    dirpath='/kaggle/working/weigths',\n",
    "    filename='best_model',\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "mix = Cutmix(\n",
    "    on_batch=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T02:48:10.977546Z",
     "iopub.status.idle": "2023-04-02T02:48:10.978084Z",
     "shell.execute_reply": "2023-04-02T02:48:10.977840Z",
     "shell.execute_reply.started": "2023-04-02T02:48:10.977811Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type                    | Params\n",
      "---------------------------------------------------\n",
      "0 | model  | EdgeNeXt                | 17.9 M\n",
      "1 | loss_f | AsymmetricLossOptimized | 0     \n",
      "---------------------------------------------------\n",
      "17.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.9 M    Total params\n",
      "71.775    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fafbe6f3c24e509394716f9d4a1a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner = ClassificationLearner(\n",
    "    model=model,\n",
    "    loss=loss_f,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    train_metrics=train_metrics,\n",
    "    val_metrics=val_metrics,\n",
    "    data_keys=['image'],\n",
    "    target_keys=['target'],\n",
    "    multilabel=True\n",
    ")\n",
    "trainer = Trainer(\n",
    "    gpus=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=num_epochs,\n",
    "    # logger=WandbLogger()\n",
    ")\n",
    "trainer.fit(learner, train_dataloaders=train_dataloader, val_dataloaders=[val_dataloader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-02T02:48:10.980781Z",
     "iopub.status.idle": "2023-04-02T02:48:10.981758Z",
     "shell.execute_reply": "2023-04-02T02:48:10.981475Z",
     "shell.execute_reply.started": "2023-04-02T02:48:10.981447Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(learner.state_dict(), 'checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание прогнозов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learner\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\User\\checkpoint.pt\"))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = r\"C:\\Users\\User\\Downloads\\vk-made-sports-image-classification\\test\"\n",
    "image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.jpeg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(image_paths) == 19446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce48edc00c64d848d3d2cea369202c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "with open(import csv\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "with open('predictions.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['', 'label'])\n",
    "\n",
    "    for image_path in tqdm(image_paths):\n",
    "        image = np.array(Image.open(image_path).convert('RGB'))\n",
    "        image_tensor = val_transform(image=image)\n",
    "        image_tensor = image_tensor['image'].unsqueeze(0)\n",
    "        output = model(image_tensor)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        filename = os.path.basename(image_path)\n",
    "        label = predicted.item()\n",
    "\n",
    "        writer.writerow([filename, label]), mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['', 'label'])\n",
    "\n",
    "    for image_path in tqdm(image_paths):\n",
    "        image = np.array(Image.open(image_path).convert('RGB'))\n",
    "        image_tensor = val_transform(image=image)\n",
    "        image_tensor = image_tensor['image'].unsqueeze(0)\n",
    "        output = model(image_tensor)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        filename = os.path.basename(image_path)\n",
    "        label = predicted.item()\n",
    "\n",
    "        writer.writerow([filename, label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00043dc0-09ad-4f3f-9c8b-e7bbd0d2bacf.jpeg</td>\n",
       "      <td>fencing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005631f-7494-41cb-b759-1b357191624c.jpeg</td>\n",
       "      <td>hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0005ae5d-41f5-4f96-90f2-4180a396e892.jpeg</td>\n",
       "      <td>greco-Roman_wrestling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0007c3d6-8f43-4ca0-8f7d-d017310f4f11.jpeg</td>\n",
       "      <td>gymnastics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000990a7-897b-4731-8257-24c9d41cc6ec.jpeg</td>\n",
       "      <td>pole_vault</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image_id                  label\n",
       "0  00043dc0-09ad-4f3f-9c8b-e7bbd0d2bacf.jpeg                fencing\n",
       "1  0005631f-7494-41cb-b759-1b357191624c.jpeg                 hockey\n",
       "2  0005ae5d-41f5-4f96-90f2-4180a396e892.jpeg  greco-Roman_wrestling\n",
       "3  0007c3d6-8f43-4ca0-8f7d-d017310f4f11.jpeg             gymnastics\n",
       "4  000990a7-897b-4731-8257-24c9d41cc6ec.jpeg             pole_vault"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(columns={'Unnamed: 0': 'image_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00043dc0-09ad-4f3f-9c8b-e7bbd0d2bacf.jpeg</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005631f-7494-41cb-b759-1b357191624c.jpeg</td>\n",
       "      <td>horseback_riding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0005ae5d-41f5-4f96-90f2-4180a396e892.jpeg</td>\n",
       "      <td>gymnastics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0007c3d6-8f43-4ca0-8f7d-d017310f4f11.jpeg</td>\n",
       "      <td>handball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000990a7-897b-4731-8257-24c9d41cc6ec.jpeg</td>\n",
       "      <td>rugby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image_id             label\n",
       "0  00043dc0-09ad-4f3f-9c8b-e7bbd0d2bacf.jpeg          football\n",
       "1  0005631f-7494-41cb-b759-1b357191624c.jpeg  horseback_riding\n",
       "2  0005ae5d-41f5-4f96-90f2-4180a396e892.jpeg        gymnastics\n",
       "3  0007c3d6-8f43-4ca0-8f7d-d017310f4f11.jpeg          handball\n",
       "4  000990a7-897b-4731-8257-24c9d41cc6ec.jpeg             rugby"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {0: 'alpinism', 1: 'archery', 2: 'arm_wrestling', 3: 'badminton', 4: 'basketball', 5: 'boating', 6: 'boxing', 7: 'fencing', 8: 'football', 9: 'golf', 10: 'greco-Roman_wrestling', 11: 'gymnastics', 12: 'handball', 13: 'hockey', 14: 'horseback_riding', 15: 'javelin-throwing', 16: 'pole_vault', 17: 'rugby', 18: 'running', 19: 'sailing', 20: 'sambo', 21: 'skating', 22: 'ski_race', 23: 'surfing', 24: 'swimming', 25: 'taekwondo', 26: 'tennis', 27: 'velo', 28: 'volleyball', 29: 'water_polo'}\n",
    "\n",
    "df['label'] = df['label'].map(class_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
